{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rounding_can_fuck_off(x):\n",
    "    return np.floor(x) if ((x) - int(x)) < 0.5 else np.ceil(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')\n",
    "bs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Read data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attributes = pd.read_csv(data_path/'attributes.csv.zip', compression='zip', encoding='latin1')\n",
    "train = pd.read_csv(data_path/'train.csv.zip', compression='zip', encoding='latin1')\n",
    "test = pd.read_csv(data_path/'test.csv.zip', compression='zip', encoding='latin1')\n",
    "product_desc = pd.read_csv(data_path/'product_descriptions.csv.zip', compression='zip', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "product_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # # Deal with N/As in attributes data (drop empty records and fill in name and values with empty string)\n",
    "attr = attributes.dropna(how='all')\n",
    "attr.loc[:, ['name','value']] = attr.loc[:, ['name','value']].fillna('')\n",
    "\n",
    "# # # Ensure UID is int\n",
    "attr.loc[:, 'product_uid'] = attr.loc[:, 'product_uid'].apply(lambda x: int(x))\n",
    "\n",
    "# # # If \"bullet\" in attribute name then asserting name is meaningless - make an empty string\n",
    "attr.loc[:, 'name'] = attr.loc[:, 'name'].apply(lambda x: '' if \"Bullet\" in x else x)\n",
    "\n",
    "# # # Group name and value in attributes into single column, separated by a tab and ending in newline (for grouping stage next)\n",
    "attr.loc[:, 'attributes'] = r' \\ans ' + attr.loc[:, 'name'] + r' \\ane \\avs ' + attr.loc[:, 'value'] + r' \\ave '\n",
    "\n",
    "# # # Drop name and values, groupby UID and sum grouped values, reset index...\n",
    "# # # ...(ie. all attributes in single cell now, separated by newlines as set up above)\n",
    "attr = attr.drop(['name','value'], axis=1).groupby('product_uid').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # # Merge all data into one master dataframe by merging descriptions and attributes onto training data on UID...\n",
    "# # # ...Fill any NAs with empty string\n",
    "data = pd.merge(train, product_desc, how='left', on='product_uid')\\\n",
    ".drop('id', axis=1)\\\n",
    ".merge(attr, on='product_uid', how='left')\\\n",
    ".fillna('')\n",
    "\n",
    "# # # Finally create a master index column, which will be used to reference individual search terms\n",
    "data = data.reset_index(drop=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'relevance'] = data.loc[:, 'relevance'].apply(rounding_can_fuck_off).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['text'] = \\\n",
    "' \\ss ' + data.loc[:, 'search_term'] + ' \\es ' +\\\n",
    "' \\spt ' + data.loc[:, 'product_title'] + ' \\ept ' +\\\n",
    "' \\spd ' + data.loc[:, 'product_description'] + ' \\epd ' +\\\n",
    "data.loc[:, 'attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_data = data.drop(['product_title', 'search_term', 'product_description', 'attributes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # # Merge all data into one master dataframe by merging descriptions and attributes onto training data on UID...\n",
    "# # # ...Fill any NAs with empty string\n",
    "data = pd.merge(test, product_desc, how='left', on='product_uid')\\\n",
    ".drop('id', axis=1)\\\n",
    ".merge(attr, on='product_uid', how='left')\\\n",
    ".fillna('')\n",
    "\n",
    "# # # Finally create a master index column, which will be used to reference individual search terms\n",
    "data = data.reset_index(drop=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['text'] = \\\n",
    "' \\ss ' + data.loc[:, 'search_term'] + ' \\es ' +\\\n",
    "' \\spt ' + data.loc[:, 'product_title'] + ' \\ept ' +\\\n",
    "' \\spd ' + data.loc[:, 'product_description'] + ' \\epd ' +\\\n",
    "data.loc[:, 'attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_kaggle_data = data.drop(['product_title', 'search_term', 'product_description', 'attributes'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_data.to_csv(data_path/'train.csv')\n",
    "final_kaggle_data.to_csv(data_path/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path/'train.csv').drop('Unnamed: 0', axis=1)\n",
    "kaggle = pd.read_csv(data_path/'test.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['text'].append(kaggle['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lm = (TextList.from_df(pd.DataFrame(texts))\n",
    "#           .random_split_by_pct(0.1)\n",
    "#           .label_for_lm()\n",
    "#           .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lm.save(data_path/'data_lm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(data_path, 'data_lm.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, Transformer, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit_one_cycle(1, 3e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (216684 items)\n",
       "x: LMTextList\n",
       "xxbos \\ ss angle bracket \\ es \\ spt xxmaj simpson xxmaj strong - xxmaj tie 12-gauge xxmaj angle \\ ept \\ spd xxmaj not only do angles make joints stronger , they also provide more consistent , straight corners . xxmaj simpson xxmaj strong - xxmaj tie offers a wide variety of angles in various sizes and thicknesses to handle light - duty jobs or projects where a structural connection is needed . xxmaj some can be bent ( skewed ) to match the project . xxmaj for outdoor projects or those where moisture is present , use our xxup zmax zinc - coated connectors , which provide extra resistance against corrosion ( look for a \" z \" at the end of the model number).versatile connector for various 90 connections and home repair projectsstronger than angled nailing or screw fastening alonehelp ensure joints are consistently straight and strongdimensions : 3 in . x 3 in . x 1 - 1 / 2 in . xxmaj made from 12-gauge steelgalvanized for extra corrosion resistanceinstall with 10d common nails or # 9 x 1 - 1 / 2 in . xxmaj strong - xxmaj drive xxup sd screws \\ epd \\ ans \\ ane \\ avs xxmaj versatile connector for various xxup 90창 째 connections and home repair projects \\ ave \\ ans \\ ane \\ avs xxmaj stronger than angled nailing or screw fastening alone \\ ave \\ ans \\ ane \\ avs xxmaj help ensure joints are consistently straight and strong \\ ave \\ ans \\ ane \\ avs xxmaj dimensions : 3 in . x 3 in . x 1 - 1 / 2 in . \\ ave \\ ans \\ ane \\ avs xxmaj made from 12-gauge steel \\ ave \\ ans \\ ane \\ avs xxmaj galvanized for extra corrosion resistance \\ ave \\ ans \\ ane \\ avs xxmaj install with 10d common nails or # 9 x 1 - 1 / 2 in . xxmaj strong - xxmaj drive xxup sd screws \\ ave \\ ans xxmaj gauge \\ ane \\ avs 12 \\ ave \\ ans xxmaj material \\ ane \\ avs xxmaj galvanized xxmaj steel \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj simpson xxmaj strong - xxmaj tie \\ ave \\ ans xxmaj number of xxmaj pieces \\ ane \\ avs 1 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 1.5 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 3 \\ ave \\ ans xxmaj product xxmaj weight ( lb . ) \\ ane \\ avs 0.26 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 3 \\ ave,xxbos \\ ss l bracket \\ es \\ spt xxmaj simpson xxmaj strong - xxmaj tie 12-gauge xxmaj angle \\ ept \\ spd xxmaj not only do angles make joints stronger , they also provide more consistent , straight corners . xxmaj simpson xxmaj strong - xxmaj tie offers a wide variety of angles in various sizes and thicknesses to handle light - duty jobs or projects where a structural connection is needed . xxmaj some can be bent ( skewed ) to match the project . xxmaj for outdoor projects or those where moisture is present , use our xxup zmax zinc - coated connectors , which provide extra resistance against corrosion ( look for a \" z \" at the end of the model number).versatile connector for various 90 connections and home repair projectsstronger than angled nailing or screw fastening alonehelp ensure joints are consistently straight and strongdimensions : 3 in . x 3 in . x 1 - 1 / 2 in . xxmaj made from 12-gauge steelgalvanized for extra corrosion resistanceinstall with 10d common nails or # 9 x 1 - 1 / 2 in . xxmaj strong - xxmaj drive xxup sd screws \\ epd \\ ans \\ ane \\ avs xxmaj versatile connector for various xxup 90창 째 connections and home repair projects \\ ave \\ ans \\ ane \\ avs xxmaj stronger than angled nailing or screw fastening alone \\ ave \\ ans \\ ane \\ avs xxmaj help ensure joints are consistently straight and strong \\ ave \\ ans \\ ane \\ avs xxmaj dimensions : 3 in . x 3 in . x 1 - 1 / 2 in . \\ ave \\ ans \\ ane \\ avs xxmaj made from 12-gauge steel \\ ave \\ ans \\ ane \\ avs xxmaj galvanized for extra corrosion resistance \\ ave \\ ans \\ ane \\ avs xxmaj install with 10d common nails or # 9 x 1 - 1 / 2 in . xxmaj strong - xxmaj drive xxup sd screws \\ ave \\ ans xxmaj gauge \\ ane \\ avs 12 \\ ave \\ ans xxmaj material \\ ane \\ avs xxmaj galvanized xxmaj steel \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj simpson xxmaj strong - xxmaj tie \\ ave \\ ans xxmaj number of xxmaj pieces \\ ane \\ avs 1 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 1.5 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 3 \\ ave \\ ans xxmaj product xxmaj weight ( lb . ) \\ ane \\ avs 0.26 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 3 \\ ave,xxbos \\ ss deck over \\ es \\ spt xxup behr xxmaj premium xxmaj textured deckover 1-gal . # xxup xxunk xxmaj xxunk xxmaj wood and xxmaj concrete xxmaj coating \\ ept \\ spd xxup behr xxmaj premium xxmaj textured xxup deckover is an innovative solid color coating . xxmaj it will bring your old , weathered wood or concrete back to life . xxmaj the advanced 100 % acrylic resin formula creates a durable coating for your tired and worn out deck , rejuvenating to a whole new look . xxmaj for the best results , be sure to properly prepare the surface using other applicable xxup behr products displayed above . xxmaj california residents : see & xxmaj proposition 65 informationrevives wood and composite decks , railings , porches and boat docks , also great for concrete pool decks , patios and sidewalks100 % acrylic solid color coatingresists cracking and peeling and conceals splinters and cracks up to 1 / 4 in . xxmaj provides a durable , mildew resistant finishcovers up to 75 sq . ft . in 2 coats per galloncreates a textured , slip - resistant finishfor best results , prepare with the appropriate xxup behr product for your wood or concrete surfaceactual paint colors may vary from on - screen and printer representationscolors available to be tinted in most storesonline xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup me , xxup mn , xxup or , xxup ri , xxup vt \\ epd \\ ans xxmaj application xxmaj method \\ ane \\ avs xxmaj brush , xxmaj roller , xxmaj spray \\ ave \\ ans xxmaj assembled xxmaj depth ( in . ) \\ ane \\ avs 6.63 in \\ ave \\ ans xxmaj assembled xxmaj height ( in . ) \\ ane \\ avs 7.76 in \\ ave \\ ans xxmaj assembled xxmaj width ( in . ) \\ ane \\ avs 6.63 in \\ ave \\ ans \\ ane \\ avs xxmaj revives wood and composite decks , railings , porches and boat docks , also great for concrete pool decks , patios and sidewalks \\ ave \\ ans \\ ane \\ avs 100 % acrylic solid color coating \\ ave \\ ans \\ ane \\ avs xxmaj resists cracking and peeling and conceals splinters and cracks up to 1 / 4 in . \\ ave \\ ans \\ ane \\ avs xxmaj provides a durable , mildew resistant finish \\ ave \\ ans \\ ane \\ avs xxmaj covers up to 75 sq . ft . in 2 coats per gallon \\ ave \\ ans \\ ane \\ avs xxmaj creates a textured , slip - resistant finish \\ ave \\ ans \\ ane \\ avs xxmaj for best results , prepare with the appropriate xxup behr product for your wood or concrete surface \\ ave \\ ans \\ ane \\ avs xxmaj actual paint colors may vary from on - screen and printer representations \\ ave \\ ans \\ ane \\ avs xxmaj colors available to be tinted in most stores \\ ave \\ ans \\ ane \\ avs xxmaj online xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup me , xxup mn , xxup or , xxup ri , xxup vt \\ ave \\ ans xxmaj cleanup \\ ane \\ avs xxmaj soap and xxmaj water \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj browns / xxmaj tans \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj xxunk \\ ave \\ ans xxmaj concrete xxmaj use \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj container xxmaj size \\ ane \\ avs 1 xxup ga - xxmaj gallon \\ ave \\ ans xxmaj coverage xxmaj area ( sq . ft . ) \\ ane \\ avs 75 \\ ave \\ ans xxmaj deck xxmaj use \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj interior / xxmaj exterior \\ ane \\ avs xxmaj exterior \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxup behr xxmaj premium xxmaj textured deckover \\ ave \\ ans xxmaj mildew xxmaj resistant \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj opacity \\ ane \\ avs xxmaj solid \\ ave \\ ans xxmaj paint xxmaj product xxmaj type \\ ane \\ avs xxmaj exterior xxmaj paint / xxmaj stain \\ ave \\ ans xxmaj patching & xxmaj repair xxmaj product xxmaj type \\ ane \\ avs xxmaj restoration xxmaj coating \\ ave \\ ans xxmaj product xxmaj style \\ ane \\ avs xxmaj cottage \\ ave \\ ans xxup rgb xxmaj value \\ ane \\ avs xxunk \\ ave \\ ans xxmaj sealer \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj time before recoating ( hours ) \\ ane \\ avs 6 \\ ave \\ ans xxmaj tintable \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj transparency \\ ane \\ avs xxmaj solid \\ ave \\ ans xxup uv xxmaj resistant \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj waterproof \\ ane \\ avs xxmaj no \\ ave,xxbos \\ ss rain shower head \\ es \\ spt xxmaj delta xxmaj vero 1-handle xxmaj shower xxmaj only xxmaj faucet xxmaj trim xxmaj kit in xxmaj chrome ( xxmaj valve xxmaj not xxmaj included ) \\ ept \\ spd xxmaj update your bathroom with the xxmaj delta xxmaj vero xxmaj single - xxmaj handle xxmaj shower xxmaj faucet xxmaj trim xxmaj kit in xxmaj chrome . xxmaj it has a sleek , modern and minimalistic aesthetic . xxmaj the multichoice universal valve keeps the water temperature within + / -3 degrees xxmaj fahrenheit to help prevent scalding . xxmaj california residents : see & xxmaj proposition 65 informationincludes the trim kit only , the rough - in kit ( xxup r1 xxrep 4 0 xxup -unbx ) is sold separatelyincludes the xxunk a balanced pressure of hot and cold water even when a valve is turned on or off elsewhere in the xxunk to watersense regulations in the state of xxmaj new xxmaj york , please confirm your shipping zip code is not restricted from use of items that do not meet watersense qualifications \\ epd \\ ans xxmaj bath xxmaj faucet xxmaj type \\ ane \\ avs xxmaj combo xxmaj tub and xxmaj shower \\ ave \\ ans xxmaj built - in xxmaj water xxmaj filter \\ ane \\ avs xxmaj no \\ ave \\ ans \\ ane \\ avs xxmaj includes the trim kit only , the rough - in kit ( xxup r1 xxrep 4 0 xxup -unbx ) is sold separately \\ ave \\ ans \\ ane \\ avs xxmaj includes the handle \\ ave \\ ans \\ ane \\ avs xxmaj maintains a balanced pressure of hot and cold water even when a valve is turned on or off elsewhere in the system \\ ave \\ ans \\ ane \\ avs xxmaj due to watersense regulations in the state of xxmaj new xxmaj york , please confirm your shipping zip code is not restricted from use of items that do not meet watersense qualifications \\ ave \\ ans xxmaj certifications and xxmaj listings \\ ane \\ avs xxup ada xxmaj compliant , xxup csa xxmaj certified , xxup iapmo xxmaj certified \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj chrome \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj chrome \\ ave \\ ans xxmaj connection size ( in . ) \\ ane \\ avs 1 / 2 xxmaj in . \\ ave \\ ans xxmaj faucet xxmaj features \\ ane \\ avs xxmaj no xxmaj additional xxmaj features \\ ave \\ ans xxmaj faucet xxmaj included xxmaj components \\ ane \\ avs xxmaj handles , xxmaj pressure xxmaj balance / xxmaj scald xxmaj guard \\ ave \\ ans xxmaj faucet type \\ ane \\ avs xxmaj bath xxmaj faucet \\ ave \\ ans xxmaj flow rate ( gallons per minute ) \\ ane \\ avs 2.5 \\ ave \\ ans xxmaj handle type \\ ane \\ avs xxmaj lever \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj delta \\ ave \\ ans xxmaj number of xxmaj faucet xxmaj handles \\ ane \\ avs xxmaj single xxmaj handle \\ ave \\ ans xxmaj number of showerheads \\ ane \\ avs 1 \\ ave \\ ans xxmaj number of xxmaj spray xxmaj settings \\ ane \\ avs 1 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 15.28 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 24 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 7.09 \\ ave \\ ans xxmaj showerhead face diameter ( in . ) \\ ane \\ avs 4.06 \\ ave \\ ans xxmaj showerhead type \\ ane \\ avs xxmaj fixed xxmaj mount \\ ave \\ ans xxmaj spray xxmaj pattern \\ ane \\ avs xxmaj rain \\ ave,xxbos \\ ss shower only faucet \\ es \\ spt xxmaj delta xxmaj vero 1-handle xxmaj shower xxmaj only xxmaj faucet xxmaj trim xxmaj kit in xxmaj chrome ( xxmaj valve xxmaj not xxmaj included ) \\ ept \\ spd xxmaj update your bathroom with the xxmaj delta xxmaj vero xxmaj single - xxmaj handle xxmaj shower xxmaj faucet xxmaj trim xxmaj kit in xxmaj chrome . xxmaj it has a sleek , modern and minimalistic aesthetic . xxmaj the multichoice universal valve keeps the water temperature within + / -3 degrees xxmaj fahrenheit to help prevent scalding . xxmaj california residents : see & xxmaj proposition 65 informationincludes the trim kit only , the rough - in kit ( xxup r1 xxrep 4 0 xxup -unbx ) is sold separatelyincludes the xxunk a balanced pressure of hot and cold water even when a valve is turned on or off elsewhere in the xxunk to watersense regulations in the state of xxmaj new xxmaj york , please confirm your shipping zip code is not restricted from use of items that do not meet watersense qualifications \\ epd \\ ans xxmaj bath xxmaj faucet xxmaj type \\ ane \\ avs xxmaj combo xxmaj tub and xxmaj shower \\ ave \\ ans xxmaj built - in xxmaj water xxmaj filter \\ ane \\ avs xxmaj no \\ ave \\ ans \\ ane \\ avs xxmaj includes the trim kit only , the rough - in kit ( xxup r1 xxrep 4 0 xxup -unbx ) is sold separately \\ ave \\ ans \\ ane \\ avs xxmaj includes the handle \\ ave \\ ans \\ ane \\ avs xxmaj maintains a balanced pressure of hot and cold water even when a valve is turned on or off elsewhere in the system \\ ave \\ ans \\ ane \\ avs xxmaj due to watersense regulations in the state of xxmaj new xxmaj york , please confirm your shipping zip code is not restricted from use of items that do not meet watersense qualifications \\ ave \\ ans xxmaj certifications and xxmaj listings \\ ane \\ avs xxup ada xxmaj compliant , xxup csa xxmaj certified , xxup iapmo xxmaj certified \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj chrome \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj chrome \\ ave \\ ans xxmaj connection size ( in . ) \\ ane \\ avs 1 / 2 xxmaj in . \\ ave \\ ans xxmaj faucet xxmaj features \\ ane \\ avs xxmaj no xxmaj additional xxmaj features \\ ave \\ ans xxmaj faucet xxmaj included xxmaj components \\ ane \\ avs xxmaj handles , xxmaj pressure xxmaj balance / xxmaj scald xxmaj guard \\ ave \\ ans xxmaj faucet type \\ ane \\ avs xxmaj bath xxmaj faucet \\ ave \\ ans xxmaj flow rate ( gallons per minute ) \\ ane \\ avs 2.5 \\ ave \\ ans xxmaj handle type \\ ane \\ avs xxmaj lever \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj delta \\ ave \\ ans xxmaj number of xxmaj faucet xxmaj handles \\ ane \\ avs xxmaj single xxmaj handle \\ ave \\ ans xxmaj number of showerheads \\ ane \\ avs 1 \\ ave \\ ans xxmaj number of xxmaj spray xxmaj settings \\ ane \\ avs 1 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 15.28 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 24 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 7.09 \\ ave \\ ans xxmaj showerhead face diameter ( in . ) \\ ane \\ avs 4.06 \\ ave \\ ans xxmaj showerhead type \\ ane \\ avs xxmaj fixed xxmaj mount \\ ave \\ ans xxmaj spray xxmaj pattern \\ ane \\ avs xxmaj rain \\ ave\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (24076 items)\n",
       "x: LMTextList\n",
       "xxbos \\ ss sliding drawers \\ es \\ spt xxmaj rev - a - xxmaj shelf 19 in . h x 15 in . w x 22 in . d 2-tier xxmaj pull - xxmaj out xxmaj wire xxmaj basket xxmaj base xxmaj cabinet in xxmaj chrome \\ ept \\ spd xxmaj rethink the way you store your pots and pans with this xxmaj medium 2-tier xxmaj wire xxmaj basket xxmaj system from xxmaj rev - a - xxmaj shelf . xxmaj with full - extension , ball - bearing slides and heavy duty , chrome - plated baskets , your kitchen necessities roll out to greet you . xxmaj the 2 tiers function independently and hold up to 100 pounds each so there 's no fear of overloading or bending the wires . xxmaj these baskets will change the way you organize your cabinets . xxmaj each basket features 100 lb . weight xxunk , side and rear mounting for total stability2 tiers operate xxunk - gauge wire constructionlimited lifetime warrantyoptional door mount kit available ( xxup 5wb - xxunk door mount kit available ( xxup 5wb - xxup dmkit ) for 1-step operationlimited lifetime warranty \\ epd \\ ans \\ ane \\ avs xxmaj each basket features 100 lb . weight capacity \\ ave \\ ans \\ ane \\ avs xxmaj bottom , side and rear mounting for total stability \\ ave \\ ans \\ ane \\ avs 2 tiers operate independently \\ ave \\ ans \\ ane \\ avs xxmaj heavy - gauge wire construction \\ ave \\ ans \\ ane \\ avs xxmaj limited lifetime warranty \\ ave \\ ans \\ ane \\ avs xxmaj optional door mount kit available ( xxup 5wb - xxup dmkit ) \\ ave \\ ans \\ ane \\ avs xxmaj optional door mount kit available ( xxup 5wb - xxup dmkit ) for 1-step operation \\ ave \\ ans \\ ane \\ avs xxmaj limited lifetime warranty \\ ave \\ ans xxmaj cabinet xxmaj type \\ ane \\ avs xxmaj kitchen base cabinet \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj silver metallic \\ ave \\ ans xxmaj installation xxmaj method \\ ane \\ avs xxmaj in - xxmaj cabinet \\ ave \\ ans xxmaj kitchen xxmaj product xxmaj type \\ ane \\ avs xxmaj kitchen xxmaj accessory \\ ave \\ ans xxmaj material \\ ane \\ avs xxmaj steel \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj rev - a - xxmaj shelf \\ ave \\ ans xxmaj minimum xxmaj cabinet xxmaj opening ( in . ) \\ ane \\ avs 14.5 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 22 in \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 19 in \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 14.75 in \\ ave,xxbos \\ ss 3-light mini pendants \\ es \\ spt xxmaj varaluz xxmaj satisfaction 3-light xxmaj statue xxmaj garden xxmaj mini xxmaj pendant \\ ept \\ spd xxmaj ca n't get any satisfaction . xxmaj let us help you with that . xxmaj satisfaction was born of our desire to satisfy you . xxmaj sorry for that . xxmaj painful xxunk are our xxunk - xxunk fixtures , our strength . xxmaj hand forged of recycled steel , slat is dressed to get noticed in bright , modern finishes . xxmaj constructed from hand - forged recycled steelaccommodates three 100-watt xxup e26 base bulbs ( not included)fixture dimension : 18 in . xxmaj dia x 30.625 in . xxunk dimension : 5.5 in . xxmaj dia x 1 in . hincludes enough cable for a 10 ft . drop \\ epd \\ ans xxmaj adjustable hanging length \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj adjustable xxmaj lamp xxmaj head \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj bulb xxmaj type xxmaj included \\ ane \\ avs xxmaj incandescent , xxmaj no xxmaj bulbs xxmaj included \\ ave \\ ans xxmaj bulb(s ) xxmaj included \\ ane \\ avs xxmaj no \\ ave \\ ans \\ ane \\ avs xxmaj constructed from hand - forged recycled steel \\ ave \\ ans \\ ane \\ avs xxmaj accommodates three 100-watt xxup e26 base bulbs ( not included ) \\ ave \\ ans \\ ane \\ avs xxmaj fixture dimension : 18 in . xxmaj dia x 30.625 in . h \\ ave \\ ans \\ ane \\ avs xxmaj canopy dimension : 5.5 in . xxmaj dia x 1 in . h \\ ave \\ ans \\ ane \\ avs xxmaj includes enough cable for a 10 ft . drop \\ ave \\ ans xxmaj certifications and xxmaj listings \\ ane \\ avs xxup 1-ul xxmaj listed \\ ave \\ ans xxmaj chandelier / xxmaj pendant xxmaj type \\ ane \\ avs xxmaj cage \\ ave \\ ans xxmaj connection xxmaj type \\ ane \\ avs xxmaj hardwired \\ ave \\ ans xxup energy xxup star xxmaj certified \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj fixture xxmaj color / xxmaj finish \\ ane \\ avs xxmaj statue xxmaj garden \\ ave \\ ans xxmaj fixture xxmaj color / xxmaj finish xxmaj family \\ ane \\ avs xxmaj bronze \\ ave \\ ans xxmaj fixture depth ( in . ) \\ ane \\ avs 18 \\ ave \\ ans xxmaj fixture height ( in . ) \\ ane \\ avs 30.625 \\ ave \\ ans xxmaj fixture width ( in . ) \\ ane \\ avs 18 \\ ave \\ ans xxmaj hardwired or xxmaj plug - xxmaj in \\ ane \\ avs xxmaj hardwired \\ ave \\ ans xxmaj included \\ ane \\ avs xxmaj hardware xxmaj included \\ ave \\ ans xxmaj light xxmaj bulb xxmaj base xxmaj code \\ ane \\ avs xxup e26 \\ ave \\ ans xxmaj light xxmaj source \\ ane \\ avs xxmaj incandescent \\ ave \\ ans xxmaj maximum xxmaj bulb xxmaj wattage \\ ane \\ avs 100 w \\ ave \\ ans xxmaj maximum xxmaj hanging xxmaj length ( in . ) \\ ane \\ avs 120 \\ ave \\ ans xxmaj maximum xxmaj wattage ( watts ) \\ ane \\ avs 300 \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj varaluz \\ ave \\ ans xxmaj number of xxmaj bulbs xxmaj required \\ ane \\ avs 3 \\ ave \\ ans xxmaj pendant xxmaj type \\ ane \\ avs xxmaj large xxmaj pendant \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 18 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 30.625 \\ ave \\ ans xxmaj product xxmaj weight ( lb . ) \\ ane \\ avs 16 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 18 \\ ave \\ ans xxmaj recommended bulb type \\ ane \\ avs xxup e-26 \\ ave \\ ans xxmaj recommended xxmaj light xxmaj bulb xxmaj shape xxmaj code \\ ane \\ avs xxup a19 \\ ave \\ ans xxmaj shade xxmaj color xxmaj family \\ ane \\ avs xxmaj bronze \\ ave \\ ans xxmaj wattage ( watts ) \\ ane \\ avs 100 \\ ave,xxbos \\ ss restore 2x \\ es \\ spt xxmaj rust - xxmaj oleum xxmaj restore 1 gal . xxup 2x xxmaj cobalt xxmaj solid xxmaj deck xxmaj stain with neverwet \\ ept \\ spd xxmaj restore 1 gal . xxup 2x xxmaj cobalt xxmaj solid xxmaj deck xxmaj stain is a new , innovative solid stain that requires only 1-coat for total coverage . neverwet xxmaj properties in the formula extend the life of the deck by providing hydrophobic water beading and superior water repellency . xxmaj algae and mildew resistant coating is ready for full use in just 48 hours . xxmaj california residents : see & xxmaj proposition 65 informationsuitable for application on wood decks and docks , broom swept concrete and moreformulated for 1-coat application , goes twice as far saving time and moneycovers up to 250 sq . ft . in just 1-coatflat finish provides non - reflective appearance and helps hide surface imperfectionsneverwet properties in formula repel waterready for furniture and full use in 48 hours2x thicker than ordinary paintprior to application prime with xxmaj restore xxmaj deck xxmaj start xxmaj wood xxmaj primer to simplify preparation and promote top coat adhesionallow new and sealed wood decks to weather at least 6 months prior to applicationfollow specific manufacturers directions before applying to any composite deckingnot for use on smooth or floated concrete or areas that are exposed to vehicular trafficproperly clean and prepare deck , read all instructions prior to usesoap and water clean up while wetactual paint colors may varyonline xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup me , xxup mn , xxup or , xxup ri , xxup vt \\ epd \\ ans xxmaj application xxmaj method \\ ane \\ avs xxmaj brush , xxmaj roller , xxmaj spray \\ ave \\ ans \\ ane \\ avs xxmaj suitable for application on wood decks and docks , broom swept concrete and more \\ ave \\ ans \\ ane \\ avs xxmaj formulated for 1-coat application , goes twice as far saving time and money \\ ave \\ ans \\ ane \\ avs xxmaj covers up to 250 sq . ft . in just 1-coat \\ ave \\ ans \\ ane \\ avs xxmaj flat finish provides non - reflective appearance and helps hide surface imperfections \\ ave \\ ans \\ ane \\ avs neverwet properties in formula repel water \\ ave \\ ans \\ ane \\ avs xxmaj ready for furniture and full use in 48 hours \\ ave \\ ans \\ ane \\ avs xxup 2x thicker than ordinary paint \\ ave \\ ans \\ ane \\ avs xxmaj prior to application prime with xxmaj restore xxmaj deck xxmaj start xxmaj wood xxmaj primer to simplify preparation and promote top coat adhesion \\ ave \\ ans \\ ane \\ avs xxmaj allow new and sealed wood decks to weather at least 6 months prior to application \\ ave \\ ans \\ ane \\ avs xxmaj follow specific manufacturers directions before applying to any composite decking \\ ave \\ ans \\ ane \\ avs xxmaj not for use on smooth or floated concrete or areas that are exposed to vehicular traffic \\ ave \\ ans \\ ane \\ avs xxmaj properly clean and prepare deck , read all instructions prior to use \\ ave \\ ans \\ ane \\ avs xxmaj soap and water clean up while wet \\ ave \\ ans \\ ane \\ avs xxmaj actual paint colors may vary \\ ave \\ ans \\ ane \\ avs xxmaj online xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup me , xxup mn , xxup or , xxup ri , xxup vt \\ ave \\ ans xxmaj cleanup \\ ane \\ avs xxmaj soap and xxmaj water \\ ave \\ ans xxmaj coating xxmaj product xxmaj category \\ ane \\ avs xxmaj stain \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj blues \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj cobalt \\ ave \\ ans xxmaj concrete xxmaj use \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj container xxmaj size \\ ane \\ avs 1 xxup ga - xxmaj gallon \\ ave \\ ans xxmaj coverage xxmaj area ( sq . ft . ) \\ ane \\ avs 250 \\ ave \\ ans xxmaj deck xxmaj use \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj dry to touch ( min . ) \\ ane \\ avs 360 \\ ave \\ ans xxmaj interior / xxmaj exterior \\ ane \\ avs xxmaj exterior \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj rust - xxmaj oleum xxmaj restore \\ ave \\ ans xxmaj mildew xxmaj resistant \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj opacity \\ ane \\ avs xxmaj solid \\ ave \\ ans xxmaj paint xxmaj product xxmaj type \\ ane \\ avs xxmaj exterior xxmaj paint / xxmaj stain \\ ave \\ ans xxmaj paint / xxmaj stain xxmaj clean xxmaj up \\ ane \\ avs xxmaj soap & xxmaj water \\ ave \\ ans xxmaj paint / xxmaj stain xxmaj key xxmaj features \\ ane \\ avs xxmaj low xxmaj temperature , xxmaj primer xxmaj required , xxmaj tintable , xxmaj waterproof \\ ave \\ ans xxmaj paint / xxmaj stain / xxmaj waterproofer xxmaj product xxmaj type \\ ane \\ avs xxmaj deck , xxmaj house & xxmaj concrete \\ ave \\ ans xxup rgb xxmaj value \\ ane \\ avs xxunk \\ ave \\ ans xxmaj sealer \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj substrate / xxmaj surface xxmaj use xxmaj type \\ ane \\ avs xxmaj wood \\ ave \\ ans xxmaj time before recoating ( hours ) \\ ane \\ avs 0 \\ ave \\ ans xxmaj tintable \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj transparency \\ ane \\ avs xxmaj solid \\ ave \\ ans xxup uv xxmaj resistant \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj waterproof \\ ane \\ avs xxmaj yes \\ ave,xxbos \\ ss fireworks \\ es \\ spt xxmaj trademark xxmaj fine xxmaj art 24 in . x 16 in . xxmaj flower xxmaj fireworks xxmaj canvas xxmaj art \\ ept \\ spd xxmaj xxunk xxmaj xxunk has always wanted to be an artist , even as a child . a talent and appreciation passed down from her xxunk and mother , xxmaj xxunk excelled early in her career winning awards as a student . xxmaj she continues to garner xxunk and place highly at xxunk shows and exhibitions in her adult career . xxmaj she xxunk that through her work she is able to evoke hope , happiness , and understanding and sometimes even xxunk , despair or xxunk . xxmaj of her work xxmaj xxunk says , \" xxmaj nothing can compare to xxmaj xxunk 's creations , i merely want to capture those creations or situations that you may have xxunk ready to hang , gallery - wrapped art piece features botanical xxunk ( jee - clay ) is an advanced printmaking process for creating high quality fine art reproductions , the attainable excellence that giclee printmaking affords makes the reproduction virtually indistinguishable from the original pieceartist : xxmaj xxunk xxunk : floralstyle : contemporaryproduct xxmaj type : xxmaj gallery - xxmaj wrapped xxmaj canvas artmade in xxup usa \\ epd,xxbos \\ ss xxunk 5 gallon basecoat \\ es \\ spt xxup behr xxmaj premium xxmaj plus 5-gal . xxmaj ultra xxmaj pure xxmaj white xxmaj semi - xxmaj gloss xxmaj enamel xxmaj exterior xxmaj paint \\ ept \\ spd xxup behr xxmaj premium xxmaj plus xxmaj exterior xxmaj semi - xxmaj gloss xxmaj enamel is 100 % acrylic , provides a mildew resistant finish and is formulated to withstand wear . xxmaj this finish resists moisture , fading and stains ; provides ultimate durability , exceptional hide and a radiant sleek appearance . xxmaj california residents : see & xxmaj proposition 65 informationideal for wood , vinyl , doors , windows , trim , shutters , garage doors and outdoor furnitureall - climate protectionexceptional hide100 % acrylicmildew resistant finishlifetime guaranteeactual paint colors may vary from on - screen and printer representationsonline xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup mn , xxup or , xxup ri , vtclick the image below to explore xxmaj exterior xxmaj paint \\ epd \\ ans \\ ane \\ avs xxmaj ideal for wood , vinyl , doors , windows , trim , shutters , garage doors and outdoor furniture \\ ave \\ ans \\ ane \\ avs xxmaj all - climate protection \\ ave \\ ans \\ ane \\ avs xxmaj exceptional hide \\ ave \\ ans \\ ane \\ avs 100 % acrylic \\ ave \\ ans \\ ane \\ avs xxmaj mildew resistant finish \\ ave \\ ans \\ ane \\ avs xxmaj lifetime guarantee \\ ave \\ ans \\ ane \\ avs xxmaj actual paint colors may vary from on - screen and printer representations \\ ave \\ ans \\ ane \\ avs xxmaj online xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup mn , xxup or , xxup ri , xxup vt \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj whites \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj ultra xxmaj pure xxmaj white \\ ave \\ ans xxmaj container xxmaj size \\ ane \\ avs 5 xxup ga - xxmaj gallon \\ ave \\ ans xxmaj coverage xxmaj area ( sq . ft . ) \\ ane \\ avs 2000 \\ ave \\ ans xxmaj dry to touch ( min . ) \\ ane \\ avs 60 \\ ave \\ ans xxmaj interior / xxmaj exterior xxmaj paint \\ ane \\ avs xxmaj exterior xxmaj paint \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxup behr xxmaj premium xxmaj plus \\ ave \\ ans xxmaj minimum xxmaj temperature for xxmaj use ( f ) \\ ane \\ avs 50 \\ ave \\ ans xxmaj paint / xxmaj stain xxmaj clean xxmaj up \\ ane \\ avs xxmaj soap & xxmaj water \\ ave \\ ans xxmaj paint / xxmaj stain xxmaj key xxmaj features \\ ane \\ avs xxmaj mildew xxmaj resistant , xxmaj primer xxmaj required , xxmaj splatter xxmaj resistant , xxmaj tintable , xxup uv / xxmaj fade xxmaj resistant \\ ave \\ ans xxup rgb xxmaj value \\ ane \\ avs 246:248:245 \\ ave \\ ans xxmaj sheen \\ ane \\ avs xxmaj semi - xxmaj gloss \\ ave \\ ans xxmaj time before recoating ( hours ) \\ ane \\ avs 2 \\ ave \\ ans xxmaj transparency \\ ane \\ avs xxmaj solid \\ ave\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): Transformer(\n",
       "    (encoder): Embedding(60004, 768)\n",
       "    (pos_enc): Embedding(512, 768)\n",
       "    (drop_emb): Dropout(p=0.03)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60004, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f95abed0510>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../data'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (216684 items)\n",
       "x: LMTextList\n",
       "xxbos \\ ss angle bracket \\ es \\ spt xxmaj simpson xxmaj strong - xxmaj tie 12-gauge xxmaj angle \\ ept \\ spd xxmaj not only do angles make joints stronger , they also provide more consistent , straight corners . xxmaj simpson xxmaj strong - xxmaj tie offers a wide variety of angles in various sizes and thicknesses to handle light - duty jobs or projects where a structural connection is needed . xxmaj some can be bent ( skewed ) to match the project . xxmaj for outdoor projects or those where moisture is present , use our xxup zmax zinc - coated connectors , which provide extra resistance against corrosion ( look for a \" z \" at the end of the model number).versatile connector for various 90 connections and home repair projectsstronger than angled nailing or screw fastening alonehelp ensure joints are consistently straight and strongdimensions : 3 in . x 3 in . x 1 - 1 / 2 in . xxmaj made from 12-gauge steelgalvanized for extra corrosion resistanceinstall with 10d common nails or # 9 x 1 - 1 / 2 in . xxmaj strong - xxmaj drive xxup sd screws \\ epd \\ ans \\ ane \\ avs xxmaj versatile connector for various xxup 90창 째 connections and home repair projects \\ ave \\ ans \\ ane \\ avs xxmaj stronger than angled nailing or screw fastening alone \\ ave \\ ans \\ ane \\ avs xxmaj help ensure joints are consistently straight and strong \\ ave \\ ans \\ ane \\ avs xxmaj dimensions : 3 in . x 3 in . x 1 - 1 / 2 in . \\ ave \\ ans \\ ane \\ avs xxmaj made from 12-gauge steel \\ ave \\ ans \\ ane \\ avs xxmaj galvanized for extra corrosion resistance \\ ave \\ ans \\ ane \\ avs xxmaj install with 10d common nails or # 9 x 1 - 1 / 2 in . xxmaj strong - xxmaj drive xxup sd screws \\ ave \\ ans xxmaj gauge \\ ane \\ avs 12 \\ ave \\ ans xxmaj material \\ ane \\ avs xxmaj galvanized xxmaj steel \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj simpson xxmaj strong - xxmaj tie \\ ave \\ ans xxmaj number of xxmaj pieces \\ ane \\ avs 1 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 1.5 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 3 \\ ave \\ ans xxmaj product xxmaj weight ( lb . ) \\ ane \\ avs 0.26 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 3 \\ ave,xxbos \\ ss l bracket \\ es \\ spt xxmaj simpson xxmaj strong - xxmaj tie 12-gauge xxmaj angle \\ ept \\ spd xxmaj not only do angles make joints stronger , they also provide more consistent , straight corners . xxmaj simpson xxmaj strong - xxmaj tie offers a wide variety of angles in various sizes and thicknesses to handle light - duty jobs or projects where a structural connection is needed . xxmaj some can be bent ( skewed ) to match the project . xxmaj for outdoor projects or those where moisture is present , use our xxup zmax zinc - coated connectors , which provide extra resistance against corrosion ( look for a \" z \" at the end of the model number).versatile connector for various 90 connections and home repair projectsstronger than angled nailing or screw fastening alonehelp ensure joints are consistently straight and strongdimensions : 3 in . x 3 in . x 1 - 1 / 2 in . xxmaj made from 12-gauge steelgalvanized for extra corrosion resistanceinstall with 10d common nails or # 9 x 1 - 1 / 2 in . xxmaj strong - xxmaj drive xxup sd screws \\ epd \\ ans \\ ane \\ avs xxmaj versatile connector for various xxup 90창 째 connections and home repair projects \\ ave \\ ans \\ ane \\ avs xxmaj stronger than angled nailing or screw fastening alone \\ ave \\ ans \\ ane \\ avs xxmaj help ensure joints are consistently straight and strong \\ ave \\ ans \\ ane \\ avs xxmaj dimensions : 3 in . x 3 in . x 1 - 1 / 2 in . \\ ave \\ ans \\ ane \\ avs xxmaj made from 12-gauge steel \\ ave \\ ans \\ ane \\ avs xxmaj galvanized for extra corrosion resistance \\ ave \\ ans \\ ane \\ avs xxmaj install with 10d common nails or # 9 x 1 - 1 / 2 in . xxmaj strong - xxmaj drive xxup sd screws \\ ave \\ ans xxmaj gauge \\ ane \\ avs 12 \\ ave \\ ans xxmaj material \\ ane \\ avs xxmaj galvanized xxmaj steel \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj simpson xxmaj strong - xxmaj tie \\ ave \\ ans xxmaj number of xxmaj pieces \\ ane \\ avs 1 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 1.5 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 3 \\ ave \\ ans xxmaj product xxmaj weight ( lb . ) \\ ane \\ avs 0.26 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 3 \\ ave,xxbos \\ ss deck over \\ es \\ spt xxup behr xxmaj premium xxmaj textured deckover 1-gal . # xxup xxunk xxmaj xxunk xxmaj wood and xxmaj concrete xxmaj coating \\ ept \\ spd xxup behr xxmaj premium xxmaj textured xxup deckover is an innovative solid color coating . xxmaj it will bring your old , weathered wood or concrete back to life . xxmaj the advanced 100 % acrylic resin formula creates a durable coating for your tired and worn out deck , rejuvenating to a whole new look . xxmaj for the best results , be sure to properly prepare the surface using other applicable xxup behr products displayed above . xxmaj california residents : see & xxmaj proposition 65 informationrevives wood and composite decks , railings , porches and boat docks , also great for concrete pool decks , patios and sidewalks100 % acrylic solid color coatingresists cracking and peeling and conceals splinters and cracks up to 1 / 4 in . xxmaj provides a durable , mildew resistant finishcovers up to 75 sq . ft . in 2 coats per galloncreates a textured , slip - resistant finishfor best results , prepare with the appropriate xxup behr product for your wood or concrete surfaceactual paint colors may vary from on - screen and printer representationscolors available to be tinted in most storesonline xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup me , xxup mn , xxup or , xxup ri , xxup vt \\ epd \\ ans xxmaj application xxmaj method \\ ane \\ avs xxmaj brush , xxmaj roller , xxmaj spray \\ ave \\ ans xxmaj assembled xxmaj depth ( in . ) \\ ane \\ avs 6.63 in \\ ave \\ ans xxmaj assembled xxmaj height ( in . ) \\ ane \\ avs 7.76 in \\ ave \\ ans xxmaj assembled xxmaj width ( in . ) \\ ane \\ avs 6.63 in \\ ave \\ ans \\ ane \\ avs xxmaj revives wood and composite decks , railings , porches and boat docks , also great for concrete pool decks , patios and sidewalks \\ ave \\ ans \\ ane \\ avs 100 % acrylic solid color coating \\ ave \\ ans \\ ane \\ avs xxmaj resists cracking and peeling and conceals splinters and cracks up to 1 / 4 in . \\ ave \\ ans \\ ane \\ avs xxmaj provides a durable , mildew resistant finish \\ ave \\ ans \\ ane \\ avs xxmaj covers up to 75 sq . ft . in 2 coats per gallon \\ ave \\ ans \\ ane \\ avs xxmaj creates a textured , slip - resistant finish \\ ave \\ ans \\ ane \\ avs xxmaj for best results , prepare with the appropriate xxup behr product for your wood or concrete surface \\ ave \\ ans \\ ane \\ avs xxmaj actual paint colors may vary from on - screen and printer representations \\ ave \\ ans \\ ane \\ avs xxmaj colors available to be tinted in most stores \\ ave \\ ans \\ ane \\ avs xxmaj online xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup me , xxup mn , xxup or , xxup ri , xxup vt \\ ave \\ ans xxmaj cleanup \\ ane \\ avs xxmaj soap and xxmaj water \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj browns / xxmaj tans \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj xxunk \\ ave \\ ans xxmaj concrete xxmaj use \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj container xxmaj size \\ ane \\ avs 1 xxup ga - xxmaj gallon \\ ave \\ ans xxmaj coverage xxmaj area ( sq . ft . ) \\ ane \\ avs 75 \\ ave \\ ans xxmaj deck xxmaj use \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj interior / xxmaj exterior \\ ane \\ avs xxmaj exterior \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxup behr xxmaj premium xxmaj textured deckover \\ ave \\ ans xxmaj mildew xxmaj resistant \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj opacity \\ ane \\ avs xxmaj solid \\ ave \\ ans xxmaj paint xxmaj product xxmaj type \\ ane \\ avs xxmaj exterior xxmaj paint / xxmaj stain \\ ave \\ ans xxmaj patching & xxmaj repair xxmaj product xxmaj type \\ ane \\ avs xxmaj restoration xxmaj coating \\ ave \\ ans xxmaj product xxmaj style \\ ane \\ avs xxmaj cottage \\ ave \\ ans xxup rgb xxmaj value \\ ane \\ avs xxunk \\ ave \\ ans xxmaj sealer \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj time before recoating ( hours ) \\ ane \\ avs 6 \\ ave \\ ans xxmaj tintable \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj transparency \\ ane \\ avs xxmaj solid \\ ave \\ ans xxup uv xxmaj resistant \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj waterproof \\ ane \\ avs xxmaj no \\ ave,xxbos \\ ss rain shower head \\ es \\ spt xxmaj delta xxmaj vero 1-handle xxmaj shower xxmaj only xxmaj faucet xxmaj trim xxmaj kit in xxmaj chrome ( xxmaj valve xxmaj not xxmaj included ) \\ ept \\ spd xxmaj update your bathroom with the xxmaj delta xxmaj vero xxmaj single - xxmaj handle xxmaj shower xxmaj faucet xxmaj trim xxmaj kit in xxmaj chrome . xxmaj it has a sleek , modern and minimalistic aesthetic . xxmaj the multichoice universal valve keeps the water temperature within + / -3 degrees xxmaj fahrenheit to help prevent scalding . xxmaj california residents : see & xxmaj proposition 65 informationincludes the trim kit only , the rough - in kit ( xxup r1 xxrep 4 0 xxup -unbx ) is sold separatelyincludes the xxunk a balanced pressure of hot and cold water even when a valve is turned on or off elsewhere in the xxunk to watersense regulations in the state of xxmaj new xxmaj york , please confirm your shipping zip code is not restricted from use of items that do not meet watersense qualifications \\ epd \\ ans xxmaj bath xxmaj faucet xxmaj type \\ ane \\ avs xxmaj combo xxmaj tub and xxmaj shower \\ ave \\ ans xxmaj built - in xxmaj water xxmaj filter \\ ane \\ avs xxmaj no \\ ave \\ ans \\ ane \\ avs xxmaj includes the trim kit only , the rough - in kit ( xxup r1 xxrep 4 0 xxup -unbx ) is sold separately \\ ave \\ ans \\ ane \\ avs xxmaj includes the handle \\ ave \\ ans \\ ane \\ avs xxmaj maintains a balanced pressure of hot and cold water even when a valve is turned on or off elsewhere in the system \\ ave \\ ans \\ ane \\ avs xxmaj due to watersense regulations in the state of xxmaj new xxmaj york , please confirm your shipping zip code is not restricted from use of items that do not meet watersense qualifications \\ ave \\ ans xxmaj certifications and xxmaj listings \\ ane \\ avs xxup ada xxmaj compliant , xxup csa xxmaj certified , xxup iapmo xxmaj certified \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj chrome \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj chrome \\ ave \\ ans xxmaj connection size ( in . ) \\ ane \\ avs 1 / 2 xxmaj in . \\ ave \\ ans xxmaj faucet xxmaj features \\ ane \\ avs xxmaj no xxmaj additional xxmaj features \\ ave \\ ans xxmaj faucet xxmaj included xxmaj components \\ ane \\ avs xxmaj handles , xxmaj pressure xxmaj balance / xxmaj scald xxmaj guard \\ ave \\ ans xxmaj faucet type \\ ane \\ avs xxmaj bath xxmaj faucet \\ ave \\ ans xxmaj flow rate ( gallons per minute ) \\ ane \\ avs 2.5 \\ ave \\ ans xxmaj handle type \\ ane \\ avs xxmaj lever \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj delta \\ ave \\ ans xxmaj number of xxmaj faucet xxmaj handles \\ ane \\ avs xxmaj single xxmaj handle \\ ave \\ ans xxmaj number of showerheads \\ ane \\ avs 1 \\ ave \\ ans xxmaj number of xxmaj spray xxmaj settings \\ ane \\ avs 1 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 15.28 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 24 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 7.09 \\ ave \\ ans xxmaj showerhead face diameter ( in . ) \\ ane \\ avs 4.06 \\ ave \\ ans xxmaj showerhead type \\ ane \\ avs xxmaj fixed xxmaj mount \\ ave \\ ans xxmaj spray xxmaj pattern \\ ane \\ avs xxmaj rain \\ ave,xxbos \\ ss shower only faucet \\ es \\ spt xxmaj delta xxmaj vero 1-handle xxmaj shower xxmaj only xxmaj faucet xxmaj trim xxmaj kit in xxmaj chrome ( xxmaj valve xxmaj not xxmaj included ) \\ ept \\ spd xxmaj update your bathroom with the xxmaj delta xxmaj vero xxmaj single - xxmaj handle xxmaj shower xxmaj faucet xxmaj trim xxmaj kit in xxmaj chrome . xxmaj it has a sleek , modern and minimalistic aesthetic . xxmaj the multichoice universal valve keeps the water temperature within + / -3 degrees xxmaj fahrenheit to help prevent scalding . xxmaj california residents : see & xxmaj proposition 65 informationincludes the trim kit only , the rough - in kit ( xxup r1 xxrep 4 0 xxup -unbx ) is sold separatelyincludes the xxunk a balanced pressure of hot and cold water even when a valve is turned on or off elsewhere in the xxunk to watersense regulations in the state of xxmaj new xxmaj york , please confirm your shipping zip code is not restricted from use of items that do not meet watersense qualifications \\ epd \\ ans xxmaj bath xxmaj faucet xxmaj type \\ ane \\ avs xxmaj combo xxmaj tub and xxmaj shower \\ ave \\ ans xxmaj built - in xxmaj water xxmaj filter \\ ane \\ avs xxmaj no \\ ave \\ ans \\ ane \\ avs xxmaj includes the trim kit only , the rough - in kit ( xxup r1 xxrep 4 0 xxup -unbx ) is sold separately \\ ave \\ ans \\ ane \\ avs xxmaj includes the handle \\ ave \\ ans \\ ane \\ avs xxmaj maintains a balanced pressure of hot and cold water even when a valve is turned on or off elsewhere in the system \\ ave \\ ans \\ ane \\ avs xxmaj due to watersense regulations in the state of xxmaj new xxmaj york , please confirm your shipping zip code is not restricted from use of items that do not meet watersense qualifications \\ ave \\ ans xxmaj certifications and xxmaj listings \\ ane \\ avs xxup ada xxmaj compliant , xxup csa xxmaj certified , xxup iapmo xxmaj certified \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj chrome \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj chrome \\ ave \\ ans xxmaj connection size ( in . ) \\ ane \\ avs 1 / 2 xxmaj in . \\ ave \\ ans xxmaj faucet xxmaj features \\ ane \\ avs xxmaj no xxmaj additional xxmaj features \\ ave \\ ans xxmaj faucet xxmaj included xxmaj components \\ ane \\ avs xxmaj handles , xxmaj pressure xxmaj balance / xxmaj scald xxmaj guard \\ ave \\ ans xxmaj faucet type \\ ane \\ avs xxmaj bath xxmaj faucet \\ ave \\ ans xxmaj flow rate ( gallons per minute ) \\ ane \\ avs 2.5 \\ ave \\ ans xxmaj handle type \\ ane \\ avs xxmaj lever \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj delta \\ ave \\ ans xxmaj number of xxmaj faucet xxmaj handles \\ ane \\ avs xxmaj single xxmaj handle \\ ave \\ ans xxmaj number of showerheads \\ ane \\ avs 1 \\ ave \\ ans xxmaj number of xxmaj spray xxmaj settings \\ ane \\ avs 1 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 15.28 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 24 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 7.09 \\ ave \\ ans xxmaj showerhead face diameter ( in . ) \\ ane \\ avs 4.06 \\ ave \\ ans xxmaj showerhead type \\ ane \\ avs xxmaj fixed xxmaj mount \\ ave \\ ans xxmaj spray xxmaj pattern \\ ane \\ avs xxmaj rain \\ ave\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (24076 items)\n",
       "x: LMTextList\n",
       "xxbos \\ ss sliding drawers \\ es \\ spt xxmaj rev - a - xxmaj shelf 19 in . h x 15 in . w x 22 in . d 2-tier xxmaj pull - xxmaj out xxmaj wire xxmaj basket xxmaj base xxmaj cabinet in xxmaj chrome \\ ept \\ spd xxmaj rethink the way you store your pots and pans with this xxmaj medium 2-tier xxmaj wire xxmaj basket xxmaj system from xxmaj rev - a - xxmaj shelf . xxmaj with full - extension , ball - bearing slides and heavy duty , chrome - plated baskets , your kitchen necessities roll out to greet you . xxmaj the 2 tiers function independently and hold up to 100 pounds each so there 's no fear of overloading or bending the wires . xxmaj these baskets will change the way you organize your cabinets . xxmaj each basket features 100 lb . weight xxunk , side and rear mounting for total stability2 tiers operate xxunk - gauge wire constructionlimited lifetime warrantyoptional door mount kit available ( xxup 5wb - xxunk door mount kit available ( xxup 5wb - xxup dmkit ) for 1-step operationlimited lifetime warranty \\ epd \\ ans \\ ane \\ avs xxmaj each basket features 100 lb . weight capacity \\ ave \\ ans \\ ane \\ avs xxmaj bottom , side and rear mounting for total stability \\ ave \\ ans \\ ane \\ avs 2 tiers operate independently \\ ave \\ ans \\ ane \\ avs xxmaj heavy - gauge wire construction \\ ave \\ ans \\ ane \\ avs xxmaj limited lifetime warranty \\ ave \\ ans \\ ane \\ avs xxmaj optional door mount kit available ( xxup 5wb - xxup dmkit ) \\ ave \\ ans \\ ane \\ avs xxmaj optional door mount kit available ( xxup 5wb - xxup dmkit ) for 1-step operation \\ ave \\ ans \\ ane \\ avs xxmaj limited lifetime warranty \\ ave \\ ans xxmaj cabinet xxmaj type \\ ane \\ avs xxmaj kitchen base cabinet \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj silver metallic \\ ave \\ ans xxmaj installation xxmaj method \\ ane \\ avs xxmaj in - xxmaj cabinet \\ ave \\ ans xxmaj kitchen xxmaj product xxmaj type \\ ane \\ avs xxmaj kitchen xxmaj accessory \\ ave \\ ans xxmaj material \\ ane \\ avs xxmaj steel \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj rev - a - xxmaj shelf \\ ave \\ ans xxmaj minimum xxmaj cabinet xxmaj opening ( in . ) \\ ane \\ avs 14.5 \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 22 in \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 19 in \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 14.75 in \\ ave,xxbos \\ ss 3-light mini pendants \\ es \\ spt xxmaj varaluz xxmaj satisfaction 3-light xxmaj statue xxmaj garden xxmaj mini xxmaj pendant \\ ept \\ spd xxmaj ca n't get any satisfaction . xxmaj let us help you with that . xxmaj satisfaction was born of our desire to satisfy you . xxmaj sorry for that . xxmaj painful xxunk are our xxunk - xxunk fixtures , our strength . xxmaj hand forged of recycled steel , slat is dressed to get noticed in bright , modern finishes . xxmaj constructed from hand - forged recycled steelaccommodates three 100-watt xxup e26 base bulbs ( not included)fixture dimension : 18 in . xxmaj dia x 30.625 in . xxunk dimension : 5.5 in . xxmaj dia x 1 in . hincludes enough cable for a 10 ft . drop \\ epd \\ ans xxmaj adjustable hanging length \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj adjustable xxmaj lamp xxmaj head \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj bulb xxmaj type xxmaj included \\ ane \\ avs xxmaj incandescent , xxmaj no xxmaj bulbs xxmaj included \\ ave \\ ans xxmaj bulb(s ) xxmaj included \\ ane \\ avs xxmaj no \\ ave \\ ans \\ ane \\ avs xxmaj constructed from hand - forged recycled steel \\ ave \\ ans \\ ane \\ avs xxmaj accommodates three 100-watt xxup e26 base bulbs ( not included ) \\ ave \\ ans \\ ane \\ avs xxmaj fixture dimension : 18 in . xxmaj dia x 30.625 in . h \\ ave \\ ans \\ ane \\ avs xxmaj canopy dimension : 5.5 in . xxmaj dia x 1 in . h \\ ave \\ ans \\ ane \\ avs xxmaj includes enough cable for a 10 ft . drop \\ ave \\ ans xxmaj certifications and xxmaj listings \\ ane \\ avs xxup 1-ul xxmaj listed \\ ave \\ ans xxmaj chandelier / xxmaj pendant xxmaj type \\ ane \\ avs xxmaj cage \\ ave \\ ans xxmaj connection xxmaj type \\ ane \\ avs xxmaj hardwired \\ ave \\ ans xxup energy xxup star xxmaj certified \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj fixture xxmaj color / xxmaj finish \\ ane \\ avs xxmaj statue xxmaj garden \\ ave \\ ans xxmaj fixture xxmaj color / xxmaj finish xxmaj family \\ ane \\ avs xxmaj bronze \\ ave \\ ans xxmaj fixture depth ( in . ) \\ ane \\ avs 18 \\ ave \\ ans xxmaj fixture height ( in . ) \\ ane \\ avs 30.625 \\ ave \\ ans xxmaj fixture width ( in . ) \\ ane \\ avs 18 \\ ave \\ ans xxmaj hardwired or xxmaj plug - xxmaj in \\ ane \\ avs xxmaj hardwired \\ ave \\ ans xxmaj included \\ ane \\ avs xxmaj hardware xxmaj included \\ ave \\ ans xxmaj light xxmaj bulb xxmaj base xxmaj code \\ ane \\ avs xxup e26 \\ ave \\ ans xxmaj light xxmaj source \\ ane \\ avs xxmaj incandescent \\ ave \\ ans xxmaj maximum xxmaj bulb xxmaj wattage \\ ane \\ avs 100 w \\ ave \\ ans xxmaj maximum xxmaj hanging xxmaj length ( in . ) \\ ane \\ avs 120 \\ ave \\ ans xxmaj maximum xxmaj wattage ( watts ) \\ ane \\ avs 300 \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj varaluz \\ ave \\ ans xxmaj number of xxmaj bulbs xxmaj required \\ ane \\ avs 3 \\ ave \\ ans xxmaj pendant xxmaj type \\ ane \\ avs xxmaj large xxmaj pendant \\ ave \\ ans xxmaj product xxmaj depth ( in . ) \\ ane \\ avs 18 \\ ave \\ ans xxmaj product xxmaj height ( in . ) \\ ane \\ avs 30.625 \\ ave \\ ans xxmaj product xxmaj weight ( lb . ) \\ ane \\ avs 16 \\ ave \\ ans xxmaj product xxmaj width ( in . ) \\ ane \\ avs 18 \\ ave \\ ans xxmaj recommended bulb type \\ ane \\ avs xxup e-26 \\ ave \\ ans xxmaj recommended xxmaj light xxmaj bulb xxmaj shape xxmaj code \\ ane \\ avs xxup a19 \\ ave \\ ans xxmaj shade xxmaj color xxmaj family \\ ane \\ avs xxmaj bronze \\ ave \\ ans xxmaj wattage ( watts ) \\ ane \\ avs 100 \\ ave,xxbos \\ ss restore 2x \\ es \\ spt xxmaj rust - xxmaj oleum xxmaj restore 1 gal . xxup 2x xxmaj cobalt xxmaj solid xxmaj deck xxmaj stain with neverwet \\ ept \\ spd xxmaj restore 1 gal . xxup 2x xxmaj cobalt xxmaj solid xxmaj deck xxmaj stain is a new , innovative solid stain that requires only 1-coat for total coverage . neverwet xxmaj properties in the formula extend the life of the deck by providing hydrophobic water beading and superior water repellency . xxmaj algae and mildew resistant coating is ready for full use in just 48 hours . xxmaj california residents : see & xxmaj proposition 65 informationsuitable for application on wood decks and docks , broom swept concrete and moreformulated for 1-coat application , goes twice as far saving time and moneycovers up to 250 sq . ft . in just 1-coatflat finish provides non - reflective appearance and helps hide surface imperfectionsneverwet properties in formula repel waterready for furniture and full use in 48 hours2x thicker than ordinary paintprior to application prime with xxmaj restore xxmaj deck xxmaj start xxmaj wood xxmaj primer to simplify preparation and promote top coat adhesionallow new and sealed wood decks to weather at least 6 months prior to applicationfollow specific manufacturers directions before applying to any composite deckingnot for use on smooth or floated concrete or areas that are exposed to vehicular trafficproperly clean and prepare deck , read all instructions prior to usesoap and water clean up while wetactual paint colors may varyonline xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup me , xxup mn , xxup or , xxup ri , xxup vt \\ epd \\ ans xxmaj application xxmaj method \\ ane \\ avs xxmaj brush , xxmaj roller , xxmaj spray \\ ave \\ ans \\ ane \\ avs xxmaj suitable for application on wood decks and docks , broom swept concrete and more \\ ave \\ ans \\ ane \\ avs xxmaj formulated for 1-coat application , goes twice as far saving time and money \\ ave \\ ans \\ ane \\ avs xxmaj covers up to 250 sq . ft . in just 1-coat \\ ave \\ ans \\ ane \\ avs xxmaj flat finish provides non - reflective appearance and helps hide surface imperfections \\ ave \\ ans \\ ane \\ avs neverwet properties in formula repel water \\ ave \\ ans \\ ane \\ avs xxmaj ready for furniture and full use in 48 hours \\ ave \\ ans \\ ane \\ avs xxup 2x thicker than ordinary paint \\ ave \\ ans \\ ane \\ avs xxmaj prior to application prime with xxmaj restore xxmaj deck xxmaj start xxmaj wood xxmaj primer to simplify preparation and promote top coat adhesion \\ ave \\ ans \\ ane \\ avs xxmaj allow new and sealed wood decks to weather at least 6 months prior to application \\ ave \\ ans \\ ane \\ avs xxmaj follow specific manufacturers directions before applying to any composite decking \\ ave \\ ans \\ ane \\ avs xxmaj not for use on smooth or floated concrete or areas that are exposed to vehicular traffic \\ ave \\ ans \\ ane \\ avs xxmaj properly clean and prepare deck , read all instructions prior to use \\ ave \\ ans \\ ane \\ avs xxmaj soap and water clean up while wet \\ ave \\ ans \\ ane \\ avs xxmaj actual paint colors may vary \\ ave \\ ans \\ ane \\ avs xxmaj online xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup me , xxup mn , xxup or , xxup ri , xxup vt \\ ave \\ ans xxmaj cleanup \\ ane \\ avs xxmaj soap and xxmaj water \\ ave \\ ans xxmaj coating xxmaj product xxmaj category \\ ane \\ avs xxmaj stain \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj blues \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj cobalt \\ ave \\ ans xxmaj concrete xxmaj use \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj container xxmaj size \\ ane \\ avs 1 xxup ga - xxmaj gallon \\ ave \\ ans xxmaj coverage xxmaj area ( sq . ft . ) \\ ane \\ avs 250 \\ ave \\ ans xxmaj deck xxmaj use \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj dry to touch ( min . ) \\ ane \\ avs 360 \\ ave \\ ans xxmaj interior / xxmaj exterior \\ ane \\ avs xxmaj exterior \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxmaj rust - xxmaj oleum xxmaj restore \\ ave \\ ans xxmaj mildew xxmaj resistant \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj opacity \\ ane \\ avs xxmaj solid \\ ave \\ ans xxmaj paint xxmaj product xxmaj type \\ ane \\ avs xxmaj exterior xxmaj paint / xxmaj stain \\ ave \\ ans xxmaj paint / xxmaj stain xxmaj clean xxmaj up \\ ane \\ avs xxmaj soap & xxmaj water \\ ave \\ ans xxmaj paint / xxmaj stain xxmaj key xxmaj features \\ ane \\ avs xxmaj low xxmaj temperature , xxmaj primer xxmaj required , xxmaj tintable , xxmaj waterproof \\ ave \\ ans xxmaj paint / xxmaj stain / xxmaj waterproofer xxmaj product xxmaj type \\ ane \\ avs xxmaj deck , xxmaj house & xxmaj concrete \\ ave \\ ans xxup rgb xxmaj value \\ ane \\ avs xxunk \\ ave \\ ans xxmaj sealer \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj substrate / xxmaj surface xxmaj use xxmaj type \\ ane \\ avs xxmaj wood \\ ave \\ ans xxmaj time before recoating ( hours ) \\ ane \\ avs 0 \\ ave \\ ans xxmaj tintable \\ ane \\ avs xxmaj yes \\ ave \\ ans xxmaj transparency \\ ane \\ avs xxmaj solid \\ ave \\ ans xxup uv xxmaj resistant \\ ane \\ avs xxmaj no \\ ave \\ ans xxmaj waterproof \\ ane \\ avs xxmaj yes \\ ave,xxbos \\ ss fireworks \\ es \\ spt xxmaj trademark xxmaj fine xxmaj art 24 in . x 16 in . xxmaj flower xxmaj fireworks xxmaj canvas xxmaj art \\ ept \\ spd xxmaj xxunk xxmaj xxunk has always wanted to be an artist , even as a child . a talent and appreciation passed down from her xxunk and mother , xxmaj xxunk excelled early in her career winning awards as a student . xxmaj she continues to garner xxunk and place highly at xxunk shows and exhibitions in her adult career . xxmaj she xxunk that through her work she is able to evoke hope , happiness , and understanding and sometimes even xxunk , despair or xxunk . xxmaj of her work xxmaj xxunk says , \" xxmaj nothing can compare to xxmaj xxunk 's creations , i merely want to capture those creations or situations that you may have xxunk ready to hang , gallery - wrapped art piece features botanical xxunk ( jee - clay ) is an advanced printmaking process for creating high quality fine art reproductions , the attainable excellence that giclee printmaking affords makes the reproduction virtually indistinguishable from the original pieceartist : xxmaj xxunk xxunk : floralstyle : contemporaryproduct xxmaj type : xxmaj gallery - xxmaj wrapped xxmaj canvas artmade in xxup usa \\ epd,xxbos \\ ss xxunk 5 gallon basecoat \\ es \\ spt xxup behr xxmaj premium xxmaj plus 5-gal . xxmaj ultra xxmaj pure xxmaj white xxmaj semi - xxmaj gloss xxmaj enamel xxmaj exterior xxmaj paint \\ ept \\ spd xxup behr xxmaj premium xxmaj plus xxmaj exterior xxmaj semi - xxmaj gloss xxmaj enamel is 100 % acrylic , provides a mildew resistant finish and is formulated to withstand wear . xxmaj this finish resists moisture , fading and stains ; provides ultimate durability , exceptional hide and a radiant sleek appearance . xxmaj california residents : see & xxmaj proposition 65 informationideal for wood , vinyl , doors , windows , trim , shutters , garage doors and outdoor furnitureall - climate protectionexceptional hide100 % acrylicmildew resistant finishlifetime guaranteeactual paint colors may vary from on - screen and printer representationsonline xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup mn , xxup or , xxup ri , vtclick the image below to explore xxmaj exterior xxmaj paint \\ epd \\ ans \\ ane \\ avs xxmaj ideal for wood , vinyl , doors , windows , trim , shutters , garage doors and outdoor furniture \\ ave \\ ans \\ ane \\ avs xxmaj all - climate protection \\ ave \\ ans \\ ane \\ avs xxmaj exceptional hide \\ ave \\ ans \\ ane \\ avs 100 % acrylic \\ ave \\ ans \\ ane \\ avs xxmaj mildew resistant finish \\ ave \\ ans \\ ane \\ avs xxmaj lifetime guarantee \\ ave \\ ans \\ ane \\ avs xxmaj actual paint colors may vary from on - screen and printer representations \\ ave \\ ans \\ ane \\ avs xxmaj online xxmaj price includes xxmaj paint xxmaj care fee in the following states : xxup ca , xxup co , xxup ct , xxup mn , xxup or , xxup ri , xxup vt \\ ave \\ ans xxmaj color xxmaj family \\ ane \\ avs xxmaj whites \\ ave \\ ans xxmaj color / xxmaj finish \\ ane \\ avs xxmaj ultra xxmaj pure xxmaj white \\ ave \\ ans xxmaj container xxmaj size \\ ane \\ avs 5 xxup ga - xxmaj gallon \\ ave \\ ans xxmaj coverage xxmaj area ( sq . ft . ) \\ ane \\ avs 2000 \\ ave \\ ans xxmaj dry to touch ( min . ) \\ ane \\ avs 60 \\ ave \\ ans xxmaj interior / xxmaj exterior xxmaj paint \\ ane \\ avs xxmaj exterior xxmaj paint \\ ave \\ ans xxup mfg xxmaj brand xxmaj name \\ ane \\ avs xxup behr xxmaj premium xxmaj plus \\ ave \\ ans xxmaj minimum xxmaj temperature for xxmaj use ( f ) \\ ane \\ avs 50 \\ ave \\ ans xxmaj paint / xxmaj stain xxmaj clean xxmaj up \\ ane \\ avs xxmaj soap & xxmaj water \\ ave \\ ans xxmaj paint / xxmaj stain xxmaj key xxmaj features \\ ane \\ avs xxmaj mildew xxmaj resistant , xxmaj primer xxmaj required , xxmaj splatter xxmaj resistant , xxmaj tintable , xxup uv / xxmaj fade xxmaj resistant \\ ave \\ ans xxup rgb xxmaj value \\ ane \\ avs 246:248:245 \\ ave \\ ans xxmaj sheen \\ ane \\ avs xxmaj semi - xxmaj gloss \\ ave \\ ans xxmaj time before recoating ( hours ) \\ ane \\ avs 2 \\ ave \\ ans xxmaj transparency \\ ane \\ avs xxmaj solid \\ ave\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): Transformer(\n",
       "    (encoder): Embedding(60004, 768)\n",
       "    (pos_enc): Embedding(512, 768)\n",
       "    (drop_emb): Dropout(p=0.03)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.03)\n",
       "          (drop_res): Dropout(p=0.03)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.03)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60004, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f95abed0510>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../data'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): Embedding(60004, 768)\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60004, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.03)\n",
       "      (drop_res): Dropout(p=0.03)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.03)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): Embedding(60004, 768)\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60004, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='110900', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-161bd06a200b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venvs/johnny5/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start, tot_epochs=tot_epochs, \n\u001b[1;32m     21\u001b[0m                                        start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/johnny5/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 178\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/johnny5/lib/python3.7/site-packages/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             if (\"CUDA out of memory\" in str(e) or\n",
      "\u001b[0;32m~/venvs/johnny5/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/johnny5/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/johnny5/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_backward_begin\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;34m\"Handle gradient calculation on `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smooth_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
